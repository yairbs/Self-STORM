{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5be9136",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32a5cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5a3211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from skimage import io\n",
    "from skimage.filters import meijering\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.visualization import simple_norm\n",
    "\n",
    "from NormalizedData import NormalizedData\n",
    "from Models import *\n",
    "from utils import *\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d4801e-d2eb-4145-9843-af1382fc78ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Data & Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f7ecd8-55a8-44da-bd74-bf508c035690",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = 'sample_data.tif' # Enter raw data path\n",
    "normalized = False\n",
    "save_path = 'normalized_data.tif' # Enter path for saving normalized data\n",
    "\n",
    "train_dataset = NormalizedData(data_path, is_normalized=normalized, dest=save_path, mask_threshold=0.93, label_threshold=130, modified_db_size='original')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ad548b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bea17a",
   "metadata": {},
   "source": [
    "### Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65187c57-d23a-405a-9557-a082b5f37f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "scale_factor = 4\n",
    "intp_mode = 'nearest'\n",
    "\n",
    "lista_folds = 1\n",
    "kernel_size_enc = 30\n",
    "kernel_size_dec = 30\n",
    "training_iters = 1\n",
    "inference_iters = 2\n",
    "\n",
    "learning_rate = 0.001\n",
    "no_of_epochs = 25\n",
    "\n",
    "##################################### Inference function #####################################\n",
    "inference_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=2)\n",
    "def infer(model):\n",
    "    ol = []\n",
    "    for c in inference_loader:\n",
    "        with torch.no_grad():\n",
    "            _ , f_output = model(c, iters=inference_iters, interp_mode=intp_mode)\n",
    "            output = np.squeeze(f_output.cpu().numpy())\n",
    "        ol.append(output)\n",
    "    return np.concatenate(ol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d50dd4",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daf6604",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "model = DecoderEncoder(e_kernel_size=kernel_size_enc, d_kernel_size=kernel_size_dec, scale_factor=scale_factor)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion_l1 = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "outputs = []\n",
    "no_of_batches_per_epoch = len(train_dataset)//batch_size\n",
    "\n",
    "for epoch in range(no_of_epochs):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        \n",
    "        # get the input; data is a list of [inputs]\n",
    "        inpt = data\n",
    "        inpt = inpt.float()\n",
    "        inpt = inpt.to(device)\n",
    "        \n",
    "        # interpolate the input (for loss calculation)\n",
    "        inpt_interp = F.interpolate(inpt, scale_factor=scale_factor, mode=intp_mode)\n",
    "        inpt_interp = inpt_interp.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward \n",
    "        encoder_output, decoder_output = model(inpt, iters=training_iters, interp_mode=intp_mode)\n",
    "\n",
    "        # loptimize over loss\n",
    "        loss =  criterion_l1(encoder_output, inpt_interp)\n",
    "        loss.sum().backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.sum().item()\n",
    "\n",
    "    # print running loss      \n",
    "    print(f'[{epoch + 1}] loss: {running_loss / no_of_batches_per_epoch:.8f}')\n",
    "    # run inference for current epoch\n",
    "    outputs.append(infer(model))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b058a226",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Plot Results (Per Epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed43d505-2c1d-4ca2-9b57-5e8abe676917",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Plot Input & GT\n",
    "input_im = np.std(np.squeeze(train_dataset.data.cpu().numpy()), axis=0)\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(4, 4))\n",
    "ax.imshow(input_im, cmap = 'afmhot')\n",
    "ax.set_title('Input', fontdict = {'fontsize': 40})\n",
    "\n",
    "### Plot results\n",
    "r = len(outputs)//5\n",
    "fig, ax = plt.subplots(nrows=r, ncols=5, figsize=(100, r*20))\n",
    "for i in range(r*5):\n",
    "    oi = np.std(outputs[i], axis=0)\n",
    "    oi = meijering(oi,black_ridges=False, sigmas=2)\n",
    "    oi = meijering(oi,black_ridges=False, sigmas=1)\n",
    "    ax[i//5, i % 5].imshow(oi, cmap='afmhot', norm = simple_norm(oi, percent = 99.5))\n",
    "    ax[i//5, i % 5].set_title('{e} Epochs'.format(e = (i+1)), fontdict = {'fontsize': 40})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93154676-896c-4013-b8e5-79cc08ac08da",
   "metadata": {},
   "source": [
    "### Save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79029805-d27f-4179-9730-4977970c796c",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_epochs_save = 10\n",
    "save_path = \"result_image.tif\"\n",
    "\n",
    "oi = np.std(outputs[no_epochs_save-1], axis=0)\n",
    "oi = meijering(oi,black_ridges=False, sigmas=2)\n",
    "oi = meijering(oi,black_ridges=False, sigmas=1)\n",
    "io.imsave(save_path, oi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
